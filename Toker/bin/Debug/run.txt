
  Demonstrate Toker class
 =========================
  Some things this Instructor's Solution does for CSE681 Project #2:
  - collect comments as tokens
  - collect double quoted strings as tokens
  - collect single quoted strings as tokens
  - collect specified single characters as tokens
  - collect specified character pairs as tokens
  - integrate with a SemiExpression collector
  - provide the required package structure

  processing file: c:\su\temp\StatePattern_Toker_Demo-InstrSolnF2018\Toker\Test.txt
 -- line#   1 : Test
 -- line#   1 : .
 -- line#   1 : txt
 -- line#   2 : ==
 -- line#   2 : ==
 -- line#   2 : ==
 -- line#   2 : ==
 -- line#   3 : "--Test comments--"
 -- line#   5 : // this is a single line comment
 -- line#   8 : 
/*
  this is a multi line comment
  last line
*/
 -- line#   9 : "--Test quoted things--"
 -- line#  10 : abc
 -- line#  10 : "embedded string"
 -- line#  10 : 123
 -- line#  11 : "\"a quoted string\""
 -- line#  12 : this
 -- line#  12 : is
 -- line#  12 : a
 -- line#  12 : single
 -- line#  12 : quote
 -- line#  12 : 'c'
 -- line#  12 : ;
 -- line#  13 : this
 -- line#  13 : is
 -- line#  13 : a
 -- line#  13 : single
 -- line#  13 : quote
 -- line#  13 : character
 -- line#  13 : '\''
 -- line#  14 : this
 -- line#  14 : is
 -- line#  14 : a
 -- line#  14 : double
 -- line#  14 : quote
 -- line#  14 : "a literal string"
 -- line#  15 : this
 -- line#  15 : is
 -- line#  15 : a
 -- line#  15 : double
 -- line#  15 : quote
 -- line#  15 : character
 -- line#  15 : '\"'
 -- line#  16 : "---Test alphanumerics---"
 -- line#  17 : 123abc
 -- line#  17 : 4d
 -- line#  17 : 56ef
 -- line#  17 : ghi789
 -- line#  18 : "---test some combinations---"
 -- line#  19 : (
 -- line#  19 : tok
 -- line#  19 : )
 -- line#  20 : // tricky comment
 -- line#  20 : [
 -- line#  20 : 3
 -- line#  20 : ]
 -- line#  20 : 
/* another tricky comment */
 -- line#  20 : --
 -- line#  20 : >>
 -- line#  21 : \\
 -- line#  21 : "a tricky string"
 -- line#  21 : --
 -- line#  21 : >>
 -- line#  22 : ??
 -- line#  22 : 'z'
 -- line#  22 : --
 -- line#  22 : >>
 -- line#  23 : "---Test single and two char tokens---"
 -- line#  24 : <
 -- line#  24 : >
 -- line#  24 : =
 -- line#  24 : +
 -- line#  24 : *
 -- line#  24 : -
 -- line#  24 : ()
 -- line#  24 : {
 -- line#  24 : }
 -- line#  24 : []
 -- line#  25 : ////\\\\
 -- line#  25 : "---End of Test---"
 -- line#  26 : 

  processing file: c:\su\temp\StatePattern_Toker_Demo-InstrSolnF2018\Toker\Toker.cs
 -- line#   2 : /////////////////////////////////////////////////////////////////////
 -- line#   3 : // Toker.cs - Instructor's solution for Project #2                 //
 -- line#   4 : // ver 1.1                                                         //
 -- line#   5 : // Jim Fawcett, CSE681 - Software Modeling and Analysis, Fall 2018 //
 -- line#   6 : /////////////////////////////////////////////////////////////////////
 -- line#  33 : 
/*
 * Package Operations:
 * -------------------
 * Demonstrates how to build a tokenizer based on the State Pattern.
 * This Instructor's solution meets all the requirements of Project #2
 * 
 * Required Files:
 * ---------------
 * Toker.cs
 * 
 * Maintenance History
 * -------------------
 * ver 1.1 : 02 Sep 2018
 * - Changed Toker, TokenState, TokenFileSource, and TokenContext to fix a bug
 *   in setting the initial state.  These changes are cited, below.
 * - Removed TokenState state_ from toker so only TokenContext instance manages 
 *   the current state.
 * - Changed TokenFileSource() to TokenFileSource(TokenContext context) to allow the 
 *   TokenFileSource instance to set the initial state correctly.
 * - Changed TokenState.nextState() to static TokenState.nextState(TokenContext context).
 *   That allows TokenFileSource to use nextState to set the initial state correctly.
 * - Changed TokenState.nextState(context) to treat everything that is not whitespace
 *   and is not a letter or digit as punctuation.  Char.IsPunctuation was not inclusive
 *   enough for Toker.
 * - changed current_ to currentState_ for readability
 * ver 1.0 : 30 Aug 2018
 * - first release
 */
 -- line#  35 : using
 -- line#  35 : System
 -- line#  35 : ;
 -- line#  36 : using
 -- line#  36 : System
 -- line#  36 : .
 -- line#  36 : Collections
 -- line#  36 : .
 -- line#  36 : Generic
 -- line#  36 : ;
 -- line#  37 : using
 -- line#  37 : System
 -- line#  37 : .
 -- line#  37 : Linq
 -- line#  37 : ;
 -- line#  38 : using
 -- line#  38 : System
 -- line#  38 : .
 -- line#  38 : Text
 -- line#  38 : ;
 -- line#  39 : using
 -- line#  39 : System
 -- line#  39 : .
 -- line#  39 : Threading
 -- line#  39 : .
 -- line#  39 : Tasks
 -- line#  39 : ;
 -- line#  41 : namespace
 -- line#  41 : Toker
 -- line#  42 : {
 -- line#  43 : using
 -- line#  43 : Token
 -- line#  43 : =
 -- line#  43 : StringBuilder
 -- line#  43 : ;
 -- line#  46 : ///////////////////////////////////////////////////////////////////
 -- line#  47 : // ITokenSource interface
 -- line#  48 : // - Declares operations expected of any source of tokens
 -- line#  49 : // - Typically we would use either files or strings.  This demo
 -- line#  50 : //   provides a source only for Files, e.g., TokenFileSource, below.
 -- line#  51 : public
 -- line#  51 : interface
 -- line#  51 : ITokenSource
 -- line#  52 : {
 -- line#  53 : bool
 -- line#  53 : open
 -- line#  53 : (
 -- line#  53 : string
 -- line#  53 : path
 -- line#  53 : )
 -- line#  53 : ;
 -- line#  54 : void
 -- line#  54 : close
 -- line#  54 : ()
 -- line#  54 : ;
 -- line#  55 : int
 -- line#  55 : next
 -- line#  55 : ()
 -- line#  55 : ;
 -- line#  56 : int
 -- line#  56 : peek
 -- line#  56 : (
 -- line#  56 : int
 -- line#  56 : n
 -- line#  56 : =
 -- line#  56 : 0
 -- line#  56 : )
 -- line#  56 : ;
 -- line#  57 : bool
 -- line#  57 : end
 -- line#  57 : ()
 -- line#  57 : ;
 -- line#  58 : int
 -- line#  58 : lineCount
 -- line#  58 : {
 -- line#  58 : get
 -- line#  58 : ;
 -- line#  58 : set
 -- line#  58 : ;
 -- line#  58 : }
 -- line#  59 : }
 -- line#  62 : ///////////////////////////////////////////////////////////////////
 -- line#  63 : // ITokenState interface
 -- line#  64 : // - Declares operations expected of any token gathering state
 -- line#  65 : public
 -- line#  65 : interface
 -- line#  65 : ITokenState
 -- line#  66 : {
 -- line#  67 : Token
 -- line#  67 : getTok
 -- line#  67 : ()
 -- line#  67 : ;
 -- line#  68 : bool
 -- line#  68 : isDone
 -- line#  68 : ()
 -- line#  68 : ;
 -- line#  69 : }
 -- line#  72 : ///////////////////////////////////////////////////////////////////
 -- line#  73 : // Toker class
 -- line#  74 : // - applications need to use only this class to collect tokens
 -- line#  75 : public
 -- line#  75 : class
 -- line#  75 : Toker
 -- line#  76 : {
 -- line#  77 : private
 -- line#  77 : TokenContext
 -- line#  77 : context_
 -- line#  77 : ;
 -- line#  78 : // holds single instance of all states and token source
 -- line#  80 : //----< initialize state machine >-------------------------------
 -- line#  81 : public
 -- line#  81 : Toker
 -- line#  81 : ()
 -- line#  82 : {
 -- line#  83 : context_
 -- line#  83 : =
 -- line#  83 : new
 -- line#  83 : TokenContext
 -- line#  83 : ()
 -- line#  83 : ;
 -- line#  84 : // context is glue that holds all state machine parts 
 -- line#  84 : }
 -- line#  86 : //----< attempt to open source of tokens >-----------------------
 -- line#  89 : 
/*
     * If src is successfully opened, it uses TokenState.nextState(context_)
     * to set the initial state, based on the source content.
     */
 -- line#  90 : public
 -- line#  90 : bool
 -- line#  90 : open
 -- line#  90 : (
 -- line#  90 : string
 -- line#  90 : path
 -- line#  90 : )
 -- line#  91 : {
 -- line#  92 : TokenSourceFile
 -- line#  92 : src
 -- line#  92 : =
 -- line#  92 : new
 -- line#  92 : TokenSourceFile
 -- line#  92 : (
 -- line#  92 : context_
 -- line#  92 : )
 -- line#  92 : ;
 -- line#  93 : context_
 -- line#  93 : .
 -- line#  93 : src
 -- line#  93 : =
 -- line#  93 : src
 -- line#  93 : ;
 -- line#  94 : return
 -- line#  94 : src
 -- line#  94 : .
 -- line#  94 : open
 -- line#  94 : (
 -- line#  94 : path
 -- line#  94 : )
 -- line#  94 : ;
 -- line#  95 : // if true, src has set initial state
 -- line#  95 : }
 -- line#  97 : //----< close source of tokens >---------------------------------
 -- line#  98 : public
 -- line#  98 : void
 -- line#  98 : close
 -- line#  98 : ()
 -- line#  99 : {
 -- line# 100 : context_
 -- line# 100 : .
 -- line# 100 : src
 -- line# 100 : .
 -- line# 100 : close
 -- line# 100 : ()
 -- line# 100 : ;
 -- line# 101 : }
 -- line# 103 : //----< extract a single token from TokenSource >----------------
 -- line# 108 : 
/*
     * Method promises to:
     * - extract all the text for a single token
     * - leave all the text for the next token in the TokenSource
     * - discard all whitespace
     */
 -- line# 109 : public
 -- line# 109 : Token
 -- line# 109 : getTok
 -- line# 109 : ()
 -- line# 110 : {
 -- line# 111 : Token
 -- line# 111 : tok
 -- line# 111 : =
 -- line# 111 : null
 -- line# 111 : ;
 -- line# 112 : while
 -- line# 112 : (
 -- line# 112 : !
 -- line# 112 : isDone
 -- line# 112 : ()
 -- line# 112 : )
 -- line# 113 : {
 -- line# 114 : tok
 -- line# 114 : =
 -- line# 114 : context_
 -- line# 114 : .
 -- line# 114 : currentState_
 -- line# 114 : .
 -- line# 114 : getTok
 -- line# 114 : ()
 -- line# 114 : ;
 -- line# 115 : context_
 -- line# 115 : .
 -- line# 115 : currentState_
 -- line# 115 : =
 -- line# 115 : TokenState
 -- line# 115 : .
 -- line# 115 : nextState
 -- line# 115 : (
 -- line# 115 : context_
 -- line# 115 : )
 -- line# 115 : ;
 -- line# 116 : if
 -- line# 116 : (
 -- line# 116 : !
 -- line# 116 : isWhiteSpace
 -- line# 116 : (
 -- line# 116 : tok
 -- line# 116 : )
 -- line# 116 : )
 -- line# 117 : break
 -- line# 117 : ;
 -- line# 118 : }
 -- line# 119 : return
 -- line# 119 : tok
 -- line# 119 : ;
 -- line# 120 : }
 -- line# 122 : //----< has Toker reached end of its source? >-------------------
 -- line# 123 : public
 -- line# 123 : bool
 -- line# 123 : isDone
 -- line# 123 : ()
 -- line# 124 : {
 -- line# 125 : if
 -- line# 125 : (
 -- line# 125 : context_
 -- line# 125 : .
 -- line# 125 : currentState_
 -- line# 125 : ==
 -- line# 125 : null
 -- line# 125 : )
 -- line# 126 : return
 -- line# 126 : true
 -- line# 126 : ;
 -- line# 127 : return
 -- line# 127 : context_
 -- line# 127 : .
 -- line# 127 : currentState_
 -- line# 127 : .
 -- line# 127 : isDone
 -- line# 127 : ()
 -- line# 127 : ;
 -- line# 128 : }
 -- line# 130 : //----< return number of newlines encountered in file >----------
 -- line# 131 : public
 -- line# 131 : int
 -- line# 131 : lineCount
 -- line# 131 : ()
 -- line# 131 : {
 -- line# 131 : return
 -- line# 131 : context_
 -- line# 131 : .
 -- line# 131 : src
 -- line# 131 : .
 -- line# 131 : lineCount
 -- line# 131 : ;
 -- line# 131 : }
 -- line# 134 : //----< is this token whitespace? >------------------------------
 -- line# 135 : public
 -- line# 135 : static
 -- line# 135 : bool
 -- line# 135 : isWhiteSpace
 -- line# 135 : (
 -- line# 135 : Token
 -- line# 135 : tok
 -- line# 135 : )
 -- line# 136 : {
 -- line# 137 : if
 -- line# 137 : (
 -- line# 137 : tok
 -- line# 137 : ==
 -- line# 137 : null
 -- line# 137 : ||
 -- line# 137 : tok
 -- line# 137 : .
 -- line# 137 : Length
 -- line# 137 : ==
 -- line# 137 : 0
 -- line# 137 : )
 -- line# 138 : return
 -- line# 138 : false
 -- line# 138 : ;
 -- line# 139 : return
 -- line# 139 : Char
 -- line# 139 : .
 -- line# 139 : IsWhiteSpace
 -- line# 139 : (
 -- line# 139 : tok
 -- line# 139 : [
 -- line# 139 : 0
 -- line# 139 : ]
 -- line# 139 : )
 -- line# 139 : ;
 -- line# 140 : }
 -- line# 142 : //----< is this token alphanumeric? >----------------------------
 -- line# 143 : public
 -- line# 143 : static
 -- line# 143 : bool
 -- line# 143 : isAlphaNum
 -- line# 143 : (
 -- line# 143 : Token
 -- line# 143 : tok
 -- line# 143 : )
 -- line# 144 : {
 -- line# 145 : if
 -- line# 145 : (
 -- line# 145 : tok
 -- line# 145 : ==
 -- line# 145 : null
 -- line# 145 : ||
 -- line# 145 : tok
 -- line# 145 : .
 -- line# 145 : Length
 -- line# 145 : ==
 -- line# 145 : 0
 -- line# 145 : )
 -- line# 146 : return
 -- line# 146 : false
 -- line# 146 : ;
 -- line# 147 : return
 -- line# 147 : (
 -- line# 147 : Char
 -- line# 147 : .
 -- line# 147 : IsLetterOrDigit
 -- line# 147 : (
 -- line# 147 : tok
 -- line# 147 : [
 -- line# 147 : 0
 -- line# 147 : ]
 -- line# 147 : )
 -- line# 147 : ||
 -- line# 147 : tok
 -- line# 147 : [
 -- line# 147 : 0
 -- line# 147 : ]
 -- line# 147 : ==
 -- line# 147 : '_'
 -- line# 147 : )
 -- line# 147 : ;
 -- line# 148 : }
 -- line# 150 : //----< is this token punctuator? >------------------------------
 -- line# 151 : public
 -- line# 151 : static
 -- line# 151 : bool
 -- line# 151 : isPunctuator
 -- line# 151 : (
 -- line# 151 : Token
 -- line# 151 : tok
 -- line# 151 : )
 -- line# 152 : {
 -- line# 153 : if
 -- line# 153 : (
 -- line# 153 : tok
 -- line# 153 : ==
 -- line# 153 : null
 -- line# 153 : ||
 -- line# 153 : tok
 -- line# 153 : .
 -- line# 153 : Length
 -- line# 153 : ==
 -- line# 153 : 0
 -- line# 153 : )
 -- line# 154 : return
 -- line# 154 : false
 -- line# 154 : ;
 -- line# 155 : return
 -- line# 155 : (
 -- line# 155 : !
 -- line# 155 : isWhiteSpace
 -- line# 155 : (
 -- line# 155 : tok
 -- line# 155 : )
 -- line# 155 : &&
 -- line# 155 : !
 -- line# 155 : isAlphaNum
 -- line# 155 : (
 -- line# 155 : tok
 -- line# 155 : )
 -- line# 155 : )
 -- line# 155 : ;
 -- line# 156 : }
 -- line# 158 : //----< is this token a single line comment? >-------------------
 -- line# 159 : public
 -- line# 159 : static
 -- line# 159 : bool
 -- line# 159 : isSingleLineComment
 -- line# 159 : (
 -- line# 159 : Token
 -- line# 159 : tok
 -- line# 159 : )
 -- line# 160 : {
 -- line# 161 : if
 -- line# 161 : (
 -- line# 161 : tok
 -- line# 161 : ==
 -- line# 161 : null
 -- line# 161 : ||
 -- line# 161 : tok
 -- line# 161 : .
 -- line# 161 : Length
 -- line# 161 : <
 -- line# 161 : 2
 -- line# 161 : )
 -- line# 162 : return
 -- line# 162 : false
 -- line# 162 : ;
 -- line# 163 : if
 -- line# 163 : (
 -- line# 163 : tok
 -- line# 163 : [
 -- line# 163 : 0
 -- line# 163 : ]
 -- line# 163 : ==
 -- line# 163 : '/'
 -- line# 163 : &&
 -- line# 163 : tok
 -- line# 163 : [
 -- line# 163 : 1
 -- line# 163 : ]
 -- line# 163 : ==
 -- line# 163 : '/'
 -- line# 163 : )
 -- line# 164 : return
 -- line# 164 : true
 -- line# 164 : ;
 -- line# 165 : return
 -- line# 165 : false
 -- line# 165 : ;
 -- line# 166 : }
 -- line# 168 : //----< is this token a multiple line comment? >-----------------
 -- line# 169 : public
 -- line# 169 : static
 -- line# 169 : bool
 -- line# 169 : isMultipleLineComment
 -- line# 169 : (
 -- line# 169 : Token
 -- line# 169 : tok
 -- line# 169 : )
 -- line# 170 : {
 -- line# 171 : if
 -- line# 171 : (
 -- line# 171 : tok
 -- line# 171 : ==
 -- line# 171 : null
 -- line# 171 : ||
 -- line# 171 : tok
 -- line# 171 : .
 -- line# 171 : Length
 -- line# 171 : <
 -- line# 171 : 2
 -- line# 171 : )
 -- line# 172 : return
 -- line# 172 : false
 -- line# 172 : ;
 -- line# 173 : if
 -- line# 173 : (
 -- line# 173 : tok
 -- line# 173 : [
 -- line# 173 : 0
 -- line# 173 : ]
 -- line# 173 : ==
 -- line# 173 : '/'
 -- line# 173 : &&
 -- line# 173 : tok
 -- line# 173 : [
 -- line# 173 : 1
 -- line# 173 : ]
 -- line# 173 : ==
 -- line# 173 : '*'
 -- line# 173 : )
 -- line# 174 : return
 -- line# 174 : true
 -- line# 174 : ;
 -- line# 175 : return
 -- line# 175 : false
 -- line# 175 : ;
 -- line# 176 : }
 -- line# 178 : //----< is this token a double quoted string? >------------------
 -- line# 179 : public
 -- line# 179 : static
 -- line# 179 : bool
 -- line# 179 : isDoubleQuote
 -- line# 179 : (
 -- line# 179 : Token
 -- line# 179 : tok
 -- line# 179 : )
 -- line# 180 : {
 -- line# 181 : if
 -- line# 181 : (
 -- line# 181 : tok
 -- line# 181 : ==
 -- line# 181 : null
 -- line# 181 : ||
 -- line# 181 : tok
 -- line# 181 : .
 -- line# 181 : Length
 -- line# 181 : ==
 -- line# 181 : 0
 -- line# 181 : )
 -- line# 182 : return
 -- line# 182 : false
 -- line# 182 : ;
 -- line# 183 : return
 -- line# 183 : (
 -- line# 183 : tok
 -- line# 183 : [
 -- line# 183 : 0
 -- line# 183 : ]
 -- line# 183 : ==
 -- line# 183 : '\"'
 -- line# 183 : )
 -- line# 183 : ;
 -- line# 184 : }
 -- line# 186 : //----< is this token a single-quoted character? >---------------
 -- line# 187 : public
 -- line# 187 : static
 -- line# 187 : bool
 -- line# 187 : isSingleQuote
 -- line# 187 : (
 -- line# 187 : Token
 -- line# 187 : tok
 -- line# 187 : )
 -- line# 188 : {
 -- line# 189 : if
 -- line# 189 : (
 -- line# 189 : tok
 -- line# 189 : ==
 -- line# 189 : null
 -- line# 189 : ||
 -- line# 189 : tok
 -- line# 189 : .
 -- line# 189 : Length
 -- line# 189 : ==
 -- line# 189 : 0
 -- line# 189 : )
 -- line# 190 : return
 -- line# 190 : false
 -- line# 190 : ;
 -- line# 191 : return
 -- line# 191 : (
 -- line# 191 : tok
 -- line# 191 : [
 -- line# 191 : 0
 -- line# 191 : ]
 -- line# 191 : ==
 -- line# 191 : '\''
 -- line# 191 : )
 -- line# 191 : ;
 -- line# 192 : }
 -- line# 193 : }
 -- line# 195 : ///////////////////////////////////////////////////////////////////
 -- line# 196 : // TokenContext class
 -- line# 197 : // - holds all the tokenizer states
 -- line# 198 : // - holds source of tokens
 -- line# 199 : // - internal qualification limits access to this assembly
 -- line# 200 : public
 -- line# 200 : class
 -- line# 200 : TokenContext
 -- line# 201 : {
 -- line# 202 : internal
 -- line# 202 : TokenContext
 -- line# 202 : ()
 -- line# 203 : {
 -- line# 204 : wss_
 -- line# 204 : =
 -- line# 204 : new
 -- line# 204 : WhiteSpaceState
 -- line# 204 : (
 -- line# 204 : this
 -- line# 204 : )
 -- line# 204 : ;
 -- line# 205 : pcs_
 -- line# 205 : =
 -- line# 205 : new
 -- line# 205 : PunctuationState
 -- line# 205 : (
 -- line# 205 : this
 -- line# 205 : )
 -- line# 205 : ;
 -- line# 206 : ans_
 -- line# 206 : =
 -- line# 206 : new
 -- line# 206 : AlphaNumState
 -- line# 206 : (
 -- line# 206 : this
 -- line# 206 : )
 -- line# 206 : ;
 -- line# 207 : slc_
 -- line# 207 : =
 -- line# 207 : new
 -- line# 207 : SingleLineCommentState
 -- line# 207 : (
 -- line# 207 : this
 -- line# 207 : )
 -- line# 207 : ;
 -- line# 208 : mlc_
 -- line# 208 : =
 -- line# 208 : new
 -- line# 208 : MultiLineCommentState
 -- line# 208 : (
 -- line# 208 : this
 -- line# 208 : )
 -- line# 208 : ;
 -- line# 209 : squ_
 -- line# 209 : =
 -- line# 209 : new
 -- line# 209 : SingleQuoteState
 -- line# 209 : (
 -- line# 209 : this
 -- line# 209 : )
 -- line# 209 : ;
 -- line# 210 : dqu_
 -- line# 210 : =
 -- line# 210 : new
 -- line# 210 : DoubleQuoteState
 -- line# 210 : (
 -- line# 210 : this
 -- line# 210 : )
 -- line# 210 : ;
 -- line# 211 : currentState_
 -- line# 211 : =
 -- line# 211 : wss_
 -- line# 211 : ;
 -- line# 212 : }
 -- line# 213 : internal
 -- line# 213 : WhiteSpaceState
 -- line# 213 : wss_
 -- line# 213 : {
 -- line# 213 : get
 -- line# 213 : ;
 -- line# 213 : set
 -- line# 213 : ;
 -- line# 213 : }
 -- line# 214 : internal
 -- line# 214 : PunctuationState
 -- line# 214 : pcs_
 -- line# 214 : {
 -- line# 214 : get
 -- line# 214 : ;
 -- line# 214 : set
 -- line# 214 : ;
 -- line# 214 : }
 -- line# 215 : internal
 -- line# 215 : AlphaNumState
 -- line# 215 : ans_
 -- line# 215 : {
 -- line# 215 : get
 -- line# 215 : ;
 -- line# 215 : set
 -- line# 215 : ;
 -- line# 215 : }
 -- line# 216 : internal
 -- line# 216 : SingleLineCommentState
 -- line# 216 : slc_
 -- line# 216 : {
 -- line# 216 : get
 -- line# 216 : ;
 -- line# 216 : set
 -- line# 216 : ;
 -- line# 216 : }
 -- line# 217 : internal
 -- line# 217 : MultiLineCommentState
 -- line# 217 : mlc_
 -- line# 217 : {
 -- line# 217 : get
 -- line# 217 : ;
 -- line# 217 : set
 -- line# 217 : ;
 -- line# 217 : }
 -- line# 218 : internal
 -- line# 218 : SingleQuoteState
 -- line# 218 : squ_
 -- line# 218 : {
 -- line# 218 : get
 -- line# 218 : ;
 -- line# 218 : set
 -- line# 218 : ;
 -- line# 218 : }
 -- line# 219 : internal
 -- line# 219 : DoubleQuoteState
 -- line# 219 : dqu_
 -- line# 219 : {
 -- line# 219 : get
 -- line# 219 : ;
 -- line# 219 : set
 -- line# 219 : ;
 -- line# 219 : }
 -- line# 221 : internal
 -- line# 221 : TokenState
 -- line# 221 : currentState_
 -- line# 221 : {
 -- line# 221 : get
 -- line# 221 : ;
 -- line# 221 : set
 -- line# 221 : ;
 -- line# 221 : }
 -- line# 222 : internal
 -- line# 222 : ITokenSource
 -- line# 222 : src
 -- line# 222 : {
 -- line# 222 : get
 -- line# 222 : ;
 -- line# 222 : set
 -- line# 222 : ;
 -- line# 222 : }
 -- line# 223 : // can hold any derived class
 -- line# 223 : }
 -- line# 226 : ///////////////////////////////////////////////////////////////////
 -- line# 227 : // TokenState class
 -- line# 228 : // - base for all the tokenizer states
 -- line# 229 : public
 -- line# 229 : abstract
 -- line# 229 : class
 -- line# 229 : TokenState
 -- line# 229 : :
 -- line# 229 : ITokenState
 -- line# 230 : {
 -- line# 231 : internal
 -- line# 231 : HashSet
 -- line# 231 : <
 -- line# 231 : string
 -- line# 231 : >
 -- line# 231 : oneCharTokens_
 -- line# 231 : {
 -- line# 231 : get
 -- line# 231 : ;
 -- line# 231 : set
 -- line# 231 : ;
 -- line# 231 : }
 -- line# 232 : internal
 -- line# 232 : HashSet
 -- line# 232 : <
 -- line# 232 : string
 -- line# 232 : >
 -- line# 232 : twoCharTokens_
 -- line# 232 : {
 -- line# 232 : get
 -- line# 232 : ;
 -- line# 232 : set
 -- line# 232 : ;
 -- line# 232 : }
 -- line# 233 : internal
 -- line# 233 : TokenContext
 -- line# 233 : context_
 -- line# 233 : {
 -- line# 233 : get
 -- line# 233 : ;
 -- line# 233 : set
 -- line# 233 : ;
 -- line# 233 : }
 -- line# 234 : // derived classes store context ref here
 -- line# 235 : public
 -- line# 235 : TokenState
 -- line# 235 : ()
 -- line# 236 : {
 -- line# 237 : oneCharTokens_
 -- line# 237 : =
 -- line# 237 : new
 -- line# 237 : HashSet
 -- line# 237 : <
 -- line# 237 : string
 -- line# 237 : >
 -- line# 238 : {
 -- line# 239 : "<"
 -- line# 239 : ,
 -- line# 239 : ">"
 -- line# 239 : ,
 -- line# 239 : "["
 -- line# 239 : ,
 -- line# 239 : "]"
 -- line# 239 : ,
 -- line# 239 : "("
 -- line# 239 : ,
 -- line# 239 : ")"
 -- line# 239 : ,
 -- line# 239 : "{"
 -- line# 239 : ,
 -- line# 239 : "}"
 -- line# 239 : ,
 -- line# 239 : "."
 -- line# 239 : ,
 -- line# 239 : ";"
 -- line# 239 : ,
 -- line# 239 : "="
 -- line# 239 : ,
 -- line# 239 : "+"
 -- line# 239 : ,
 -- line# 239 : "-"
 -- line# 239 : ,
 -- line# 239 : "*"
 -- line# 240 : }
 -- line# 240 : ;
 -- line# 241 : twoCharTokens_
 -- line# 241 : =
 -- line# 241 : new
 -- line# 241 : HashSet
 -- line# 241 : <
 -- line# 241 : string
 -- line# 241 : >
 -- line# 242 : {
 -- line# 243 : "<<"
 -- line# 243 : ,
 -- line# 243 : ">>"
 -- line# 243 : ,
 -- line# 243 : "::"
 -- line# 243 : ,
 -- line# 243 : "++"
 -- line# 243 : ,
 -- line# 243 : "--"
 -- line# 243 : ,
 -- line# 243 : "=="
 -- line# 243 : ,
 -- line# 243 : "+="
 -- line# 243 : ,
 -- line# 243 : "-="
 -- line# 243 : ,
 -- line# 243 : "*="
 -- line# 243 : ,
 -- line# 243 : "/="
 -- line# 243 : ,
 -- line# 243 : "()"
 -- line# 243 : ,
 -- line# 243 : "[]"
 -- line# 243 : ,
 -- line# 243 : "&&"
 -- line# 243 : ,
 -- line# 243 : "||"
 -- line# 244 : }
 -- line# 244 : ;
 -- line# 245 : }
 -- line# 247 : //----< add token to special one char tokens >-------------------
 -- line# 248 : internal
 -- line# 248 : bool
 -- line# 248 : addOneCharToken
 -- line# 248 : (
 -- line# 248 : string
 -- line# 248 : oneCharTok
 -- line# 248 : )
 -- line# 249 : {
 -- line# 250 : if
 -- line# 250 : (
 -- line# 250 : oneCharTok
 -- line# 250 : .
 -- line# 250 : Length
 -- line# 250 : >
 -- line# 250 : 1
 -- line# 250 : )
 -- line# 251 : return
 -- line# 251 : false
 -- line# 251 : ;
 -- line# 252 : oneCharTokens_
 -- line# 252 : .
 -- line# 252 : Add
 -- line# 252 : (
 -- line# 252 : oneCharTok
 -- line# 252 : )
 -- line# 252 : ;
 -- line# 253 : return
 -- line# 253 : true
 -- line# 253 : ;
 -- line# 254 : }
 -- line# 256 : //----< remove token from special one char tokens >--------------
 -- line# 257 : internal
 -- line# 257 : bool
 -- line# 257 : removeOneCharToken
 -- line# 257 : (
 -- line# 257 : string
 -- line# 257 : oneCharTok
 -- line# 257 : )
 -- line# 258 : {
 -- line# 259 : return
 -- line# 259 : oneCharTokens_
 -- line# 259 : .
 -- line# 259 : Remove
 -- line# 259 : (
 -- line# 259 : oneCharTok
 -- line# 259 : )
 -- line# 259 : ;
 -- line# 260 : }
 -- line# 262 : //----< add token to special two char tokens >-------------------
 -- line# 263 : internal
 -- line# 263 : bool
 -- line# 263 : addTwoCharToken
 -- line# 263 : (
 -- line# 263 : string
 -- line# 263 : twoCharTok
 -- line# 263 : )
 -- line# 264 : {
 -- line# 265 : if
 -- line# 265 : (
 -- line# 265 : twoCharTok
 -- line# 265 : .
 -- line# 265 : Length
 -- line# 265 : !=
 -- line# 265 : 2
 -- line# 265 : )
 -- line# 266 : return
 -- line# 266 : false
 -- line# 266 : ;
 -- line# 267 : twoCharTokens_
 -- line# 267 : .
 -- line# 267 : Add
 -- line# 267 : (
 -- line# 267 : twoCharTok
 -- line# 267 : )
 -- line# 267 : ;
 -- line# 268 : return
 -- line# 268 : true
 -- line# 268 : ;
 -- line# 269 : }
 -- line# 271 : //----< remove token from special two char tokens >--------------
 -- line# 272 : internal
 -- line# 272 : bool
 -- line# 272 : removeTwoCharToken
 -- line# 272 : (
 -- line# 272 : string
 -- line# 272 : twoCharTok
 -- line# 272 : )
 -- line# 273 : {
 -- line# 274 : return
 -- line# 274 : twoCharTokens_
 -- line# 274 : .
 -- line# 274 : Remove
 -- line# 274 : (
 -- line# 274 : twoCharTok
 -- line# 274 : )
 -- line# 274 : ;
 -- line# 275 : }
 -- line# 277 : //----< delegate source opening to context's src >---------------
 -- line# 278 : public
 -- line# 278 : bool
 -- line# 278 : open
 -- line# 278 : (
 -- line# 278 : string
 -- line# 278 : path
 -- line# 278 : )
 -- line# 279 : {
 -- line# 280 : return
 -- line# 280 : context_
 -- line# 280 : .
 -- line# 280 : src
 -- line# 280 : .
 -- line# 280 : open
 -- line# 280 : (
 -- line# 280 : path
 -- line# 280 : )
 -- line# 280 : ;
 -- line# 281 : }
 -- line# 283 : //----< leave implementation to derived states >-----------------
 -- line# 284 : public
 -- line# 284 : abstract
 -- line# 284 : Token
 -- line# 284 : getTok
 -- line# 284 : ()
 -- line# 284 : ;
 -- line# 287 : //----< what's next in the TokenSource? >------------------------
 -- line# 288 : protected
 -- line# 288 : static
 -- line# 288 : bool
 -- line# 288 : isWhiteSpace
 -- line# 288 : (
 -- line# 288 : TokenContext
 -- line# 288 : context
 -- line# 288 : )
 -- line# 289 : {
 -- line# 290 : return
 -- line# 290 : Char
 -- line# 290 : .
 -- line# 290 : IsWhiteSpace
 -- line# 290 : (
 -- line# 290 : (
 -- line# 290 : char
 -- line# 290 : )
 -- line# 290 : context
 -- line# 290 : .
 -- line# 290 : src
 -- line# 290 : .
 -- line# 290 : peek
 -- line# 290 : ()
 -- line# 290 : )
 -- line# 290 : ;
 -- line# 291 : }
 -- line# 293 : //----< what's next in the TokenSource? >------------------------
 -- line# 294 : protected
 -- line# 294 : static
 -- line# 294 : bool
 -- line# 294 : isAlphaNum
 -- line# 294 : (
 -- line# 294 : TokenContext
 -- line# 294 : context
 -- line# 294 : )
 -- line# 295 : {
 -- line# 296 : char
 -- line# 296 : ch
 -- line# 296 : =
 -- line# 296 : (
 -- line# 296 : char
 -- line# 296 : )
 -- line# 296 : context
 -- line# 296 : .
 -- line# 296 : src
 -- line# 296 : .
 -- line# 296 : peek
 -- line# 296 : ()
 -- line# 296 : ;
 -- line# 297 : return
 -- line# 297 : (
 -- line# 297 : Char
 -- line# 297 : .
 -- line# 297 : IsLetterOrDigit
 -- line# 297 : (
 -- line# 297 : ch
 -- line# 297 : )
 -- line# 297 : ||
 -- line# 297 : ch
 -- line# 297 : ==
 -- line# 297 : '_'
 -- line# 297 : )
 -- line# 297 : ;
 -- line# 298 : }
 -- line# 300 : //----< what's next in the TokenSource? >------------------------
 -- line# 301 : protected
 -- line# 301 : static
 -- line# 301 : bool
 -- line# 301 : isPunctuation
 -- line# 301 : (
 -- line# 301 : TokenContext
 -- line# 301 : context
 -- line# 301 : )
 -- line# 302 : {
 -- line# 303 : return
 -- line# 303 : (
 -- line# 303 : !
 -- line# 303 : isWhiteSpace
 -- line# 303 : (
 -- line# 303 : context
 -- line# 303 : )
 -- line# 303 : &&
 -- line# 303 : !
 -- line# 303 : isAlphaNum
 -- line# 303 : (
 -- line# 303 : context
 -- line# 303 : )
 -- line# 303 : )
 -- line# 303 : ;
 -- line# 304 : }
 -- line# 306 : //----< what's next in the TokenSource? >------------------------
 -- line# 307 : protected
 -- line# 307 : static
 -- line# 307 : bool
 -- line# 307 : isSingleLineComment
 -- line# 307 : (
 -- line# 307 : TokenContext
 -- line# 307 : context
 -- line# 307 : )
 -- line# 308 : {
 -- line# 309 : int
 -- line# 309 : first
 -- line# 309 : =
 -- line# 309 : context
 -- line# 309 : .
 -- line# 309 : src
 -- line# 309 : .
 -- line# 309 : peek
 -- line# 309 : ()
 -- line# 309 : ;
 -- line# 310 : int
 -- line# 310 : second
 -- line# 310 : =
 -- line# 310 : context
 -- line# 310 : .
 -- line# 310 : src
 -- line# 310 : .
 -- line# 310 : peek
 -- line# 310 : (
 -- line# 310 : 1
 -- line# 310 : )
 -- line# 310 : ;
 -- line# 311 : char
 -- line# 311 : chFirst
 -- line# 311 : =
 -- line# 311 : (
 -- line# 311 : char
 -- line# 311 : )
 -- line# 311 : first
 -- line# 311 : ;
 -- line# 312 : char
 -- line# 312 : chSecond
 -- line# 312 : =
 -- line# 312 : (
 -- line# 312 : char
 -- line# 312 : )
 -- line# 312 : second
 -- line# 312 : ;
 -- line# 313 : return
 -- line# 313 : (
 -- line# 313 : chFirst
 -- line# 313 : ==
 -- line# 313 : '/'
 -- line# 313 : &&
 -- line# 313 : chSecond
 -- line# 313 : ==
 -- line# 313 : '/'
 -- line# 313 : )
 -- line# 313 : ;
 -- line# 314 : }
 -- line# 316 : //----< what's next in the TokenSource? >------------------------
 -- line# 317 : protected
 -- line# 317 : static
 -- line# 317 : bool
 -- line# 317 : isMultiLineComment
 -- line# 317 : (
 -- line# 317 : TokenContext
 -- line# 317 : context
 -- line# 317 : )
 -- line# 318 : {
 -- line# 319 : int
 -- line# 319 : first
 -- line# 319 : =
 -- line# 319 : context
 -- line# 319 : .
 -- line# 319 : src
 -- line# 319 : .
 -- line# 319 : peek
 -- line# 319 : ()
 -- line# 319 : ;
 -- line# 320 : int
 -- line# 320 : second
 -- line# 320 : =
 -- line# 320 : context
 -- line# 320 : .
 -- line# 320 : src
 -- line# 320 : .
 -- line# 320 : peek
 -- line# 320 : (
 -- line# 320 : 1
 -- line# 320 : )
 -- line# 320 : ;
 -- line# 321 : char
 -- line# 321 : chFirst
 -- line# 321 : =
 -- line# 321 : (
 -- line# 321 : char
 -- line# 321 : )
 -- line# 321 : first
 -- line# 321 : ;
 -- line# 322 : char
 -- line# 322 : chSecond
 -- line# 322 : =
 -- line# 322 : (
 -- line# 322 : char
 -- line# 322 : )
 -- line# 322 : second
 -- line# 322 : ;
 -- line# 323 : return
 -- line# 323 : (
 -- line# 323 : chFirst
 -- line# 323 : ==
 -- line# 323 : '/'
 -- line# 323 : &&
 -- line# 323 : chSecond
 -- line# 323 : ==
 -- line# 323 : '*'
 -- line# 323 : )
 -- line# 323 : ;
 -- line# 324 : }
 -- line# 326 : //----< what's next in the TokenSource? >------------------------
 -- line# 327 : protected
 -- line# 327 : static
 -- line# 327 : bool
 -- line# 327 : isDoubleQuote
 -- line# 327 : (
 -- line# 327 : TokenContext
 -- line# 327 : context
 -- line# 327 : )
 -- line# 328 : {
 -- line# 329 : char
 -- line# 329 : ch
 -- line# 329 : =
 -- line# 329 : (
 -- line# 329 : char
 -- line# 329 : )
 -- line# 329 : context
 -- line# 329 : .
 -- line# 329 : src
 -- line# 329 : .
 -- line# 329 : peek
 -- line# 329 : ()
 -- line# 329 : ;
 -- line# 330 : return
 -- line# 330 : (
 -- line# 330 : ch
 -- line# 330 : ==
 -- line# 330 : '\"'
 -- line# 330 : )
 -- line# 330 : ;
 -- line# 331 : }
 -- line# 333 : //----< what's next in the TokenSource? >------------------------
 -- line# 334 : protected
 -- line# 334 : static
 -- line# 334 : bool
 -- line# 334 : isSingleQuote
 -- line# 334 : (
 -- line# 334 : TokenContext
 -- line# 334 : context
 -- line# 334 : )
 -- line# 335 : {
 -- line# 336 : char
 -- line# 336 : ch
 -- line# 336 : =
 -- line# 336 : (
 -- line# 336 : char
 -- line# 336 : )
 -- line# 336 : context
 -- line# 336 : .
 -- line# 336 : src
 -- line# 336 : .
 -- line# 336 : peek
 -- line# 336 : ()
 -- line# 336 : ;
 -- line# 337 : return
 -- line# 337 : (
 -- line# 337 : ch
 -- line# 337 : ==
 -- line# 337 : '\''
 -- line# 337 : )
 -- line# 337 : ;
 -- line# 338 : }
 -- line# 340 : //----< return next state based on content of TokenSource >------
 -- line# 341 : static
 -- line# 341 : public
 -- line# 341 : TokenState
 -- line# 341 : nextState
 -- line# 341 : (
 -- line# 341 : TokenContext
 -- line# 341 : context
 -- line# 341 : )
 -- line# 342 : {
 -- line# 343 : int
 -- line# 343 : first
 -- line# 343 : =
 -- line# 343 : context
 -- line# 343 : .
 -- line# 343 : src
 -- line# 343 : .
 -- line# 343 : peek
 -- line# 343 : ()
 -- line# 343 : ;
 -- line# 344 : if
 -- line# 344 : (
 -- line# 344 : first
 -- line# 344 : <
 -- line# 344 : 0
 -- line# 344 : )
 -- line# 345 : return
 -- line# 345 : null
 -- line# 345 : ;
 -- line# 346 : char
 -- line# 346 : ch
 -- line# 346 : =
 -- line# 346 : (
 -- line# 346 : char
 -- line# 346 : )
 -- line# 346 : first
 -- line# 346 : ;
 -- line# 348 : if
 -- line# 348 : (
 -- line# 348 : Char
 -- line# 348 : .
 -- line# 348 : IsWhiteSpace
 -- line# 348 : (
 -- line# 348 : ch
 -- line# 348 : )
 -- line# 348 : )
 -- line# 349 : return
 -- line# 349 : context
 -- line# 349 : .
 -- line# 349 : wss_
 -- line# 349 : ;
 -- line# 350 : if
 -- line# 350 : (
 -- line# 350 : Char
 -- line# 350 : .
 -- line# 350 : IsLetterOrDigit
 -- line# 350 : (
 -- line# 350 : ch
 -- line# 350 : )
 -- line# 350 : ||
 -- line# 350 : ch
 -- line# 350 : ==
 -- line# 350 : '_'
 -- line# 350 : )
 -- line# 351 : return
 -- line# 351 : context
 -- line# 351 : .
 -- line# 351 : ans_
 -- line# 351 : ;
 -- line# 354 : // Test for strings and comments here since we don't
 -- line# 355 : // want them classified as punctuators.
 -- line# 356 : if
 -- line# 356 : (
 -- line# 356 : isSingleLineComment
 -- line# 356 : (
 -- line# 356 : context
 -- line# 356 : )
 -- line# 356 : )
 -- line# 357 : return
 -- line# 357 : context
 -- line# 357 : .
 -- line# 357 : slc_
 -- line# 357 : ;
 -- line# 359 : if
 -- line# 359 : (
 -- line# 359 : isMultiLineComment
 -- line# 359 : (
 -- line# 359 : context
 -- line# 359 : )
 -- line# 359 : )
 -- line# 360 : return
 -- line# 360 : context
 -- line# 360 : .
 -- line# 360 : mlc_
 -- line# 360 : ;
 -- line# 362 : if
 -- line# 362 : (
 -- line# 362 : isDoubleQuote
 -- line# 362 : (
 -- line# 362 : context
 -- line# 362 : )
 -- line# 362 : )
 -- line# 363 : return
 -- line# 363 : context
 -- line# 363 : .
 -- line# 363 : dqu_
 -- line# 363 : ;
 -- line# 365 : if
 -- line# 365 : (
 -- line# 365 : isSingleQuote
 -- line# 365 : (
 -- line# 365 : context
 -- line# 365 : )
 -- line# 365 : )
 -- line# 366 : return
 -- line# 366 : context
 -- line# 366 : .
 -- line# 366 : squ_
 -- line# 366 : ;
 -- line# 369 : // toker's definition of punctuation is anything that is not:
 -- line# 370 : // - whitespace     space, tab, newline
 -- line# 371 : // - alphanumeric   abc123
 -- line# 372 : // - comment        /* comment */ or // comment
 -- line# 373 : // - quote          'a' or "a string"
 -- line# 375 : // Char.IsPunctuation is not inclusive enough
 -- line# 376 : return
 -- line# 376 : context
 -- line# 376 : .
 -- line# 376 : pcs_
 -- line# 376 : ;
 -- line# 377 : }
 -- line# 379 : //----< has tokenizer reached the end of its source? >-----------
 -- line# 380 : public
 -- line# 380 : bool
 -- line# 380 : isDone
 -- line# 380 : ()
 -- line# 380 : {
 -- line# 381 : if
 -- line# 381 : (
 -- line# 381 : context_
 -- line# 381 : .
 -- line# 381 : src
 -- line# 381 : ==
 -- line# 381 : null
 -- line# 381 : )
 -- line# 382 : return
 -- line# 382 : true
 -- line# 382 : ;
 -- line# 383 : return
 -- line# 383 : context_
 -- line# 383 : .
 -- line# 383 : src
 -- line# 383 : .
 -- line# 383 : end
 -- line# 383 : ()
 -- line# 383 : ;
 -- line# 384 : }
 -- line# 386 : //----< helper function to handle escaped chars in states >------
 -- line# 391 : 
/*
     * Tests to see if last char in token is preceded by an odd number
     * of escape chars, e.g.:
     * \\\' is escaped
     * \\"  is not escaped
     */
 -- line# 392 : protected
 -- line# 392 : bool
 -- line# 392 : isEscaped
 -- line# 392 : (
 -- line# 392 : Token
 -- line# 392 : tok
 -- line# 392 : )
 -- line# 393 : {
 -- line# 394 : int
 -- line# 394 : size
 -- line# 394 : =
 -- line# 394 : tok
 -- line# 394 : .
 -- line# 394 : Length
 -- line# 394 : ;
 -- line# 395 : if
 -- line# 395 : (
 -- line# 395 : size
 -- line# 395 : <
 -- line# 395 : 2
 -- line# 395 : )
 -- line# 396 : return
 -- line# 396 : false
 -- line# 396 : ;
 -- line# 397 : int
 -- line# 397 : count
 -- line# 397 : =
 -- line# 397 : 0
 -- line# 397 : ;
 -- line# 398 : for
 -- line# 398 : (
 -- line# 398 : int
 -- line# 398 : i
 -- line# 398 : =
 -- line# 398 : 0
 -- line# 398 : ;
 -- line# 398 : i
 -- line# 398 : <
 -- line# 398 : size
 -- line# 398 : -
 -- line# 398 : 1
 -- line# 398 : ;
 -- line# 398 : ++
 -- line# 398 : i
 -- line# 398 : )
 -- line# 399 : {
 -- line# 400 : count
 -- line# 400 : =
 -- line# 400 : i
 -- line# 400 : %
 -- line# 400 : 2
 -- line# 400 : ;
 -- line# 401 : if
 -- line# 401 : (
 -- line# 401 : tok
 -- line# 401 : [
 -- line# 401 : size
 -- line# 401 : -
 -- line# 401 : i
 -- line# 401 : -
 -- line# 401 : 2
 -- line# 401 : ]
 -- line# 401 : !=
 -- line# 401 : '\\'
 -- line# 401 : )
 -- line# 402 : break
 -- line# 402 : ;
 -- line# 403 : }
 -- line# 404 : if
 -- line# 404 : (
 -- line# 404 : count
 -- line# 404 : ==
 -- line# 404 : 0
 -- line# 404 : )
 -- line# 405 : return
 -- line# 405 : false
 -- line# 405 : ;
 -- line# 406 : return
 -- line# 406 : true
 -- line# 406 : ;
 -- line# 407 : }
 -- line# 408 : }
 -- line# 410 : ///////////////////////////////////////////////////////////////////
 -- line# 411 : // Derived State Classes
 -- line# 431 : 
/* - WhiteSpaceState          Token with space, tab, and newline chars
   * - AlphaNumState            Token with letters and digits
   * - SingleLineCommentState   Token holding C++ style comment
   * - MultiLineCommentState    Token holding C style comment
   * - SingleQuoteState         Token holding a quoted character
   * - DoubleQuoteState         Token holding a quoted string
   * - PunctuationState         Token holding anything not included above
   * ----------------------------------------------------------------
   * - Each state class accepts a reference to the context in its
   *   constructor and saves in its inherited context_ property.
   * - It is only required to provide a getTok() method which
   *   returns a token conforming to its state, e.g., whitespace, ...
   * - getTok() assumes that the TokenSource's first character 
   *   matches its type e.g., whitespace char, ...
   * - The nextState() method ensures that the condition, above, is
   *   satisfied.
   * - The getTok() method promises not to extract characters from
   *   the TokenSource that belong to another state.
   * - These requirements lead us to depend heavily on peeking into
   *   the TokenSource's content.
   */
 -- line# 433 : ///////////////////////////////////////////////////////////////////
 -- line# 434 : // WhiteSpaceState class
 -- line# 435 : // - extracts, from context_.src, contiguous whitespace chars as token
 -- line# 436 : // - will be thrown away by tokenizer
 -- line# 437 : public
 -- line# 437 : class
 -- line# 437 : WhiteSpaceState
 -- line# 437 : :
 -- line# 437 : TokenState
 -- line# 438 : {
 -- line# 439 : public
 -- line# 439 : WhiteSpaceState
 -- line# 439 : (
 -- line# 439 : TokenContext
 -- line# 439 : context
 -- line# 439 : )
 -- line# 440 : {
 -- line# 441 : context_
 -- line# 441 : =
 -- line# 441 : context
 -- line# 441 : ;
 -- line# 442 : }
 -- line# 444 : //----< keep extracting until get non-whitespace >---------------
 -- line# 445 : override
 -- line# 445 : public
 -- line# 445 : Token
 -- line# 445 : getTok
 -- line# 445 : ()
 -- line# 446 : {
 -- line# 447 : Token
 -- line# 447 : tok
 -- line# 447 : =
 -- line# 447 : new
 -- line# 447 : Token
 -- line# 447 : ()
 -- line# 447 : ;
 -- line# 448 : tok
 -- line# 448 : .
 -- line# 448 : Append
 -- line# 448 : (
 -- line# 448 : (
 -- line# 448 : char
 -- line# 448 : )
 -- line# 448 : context_
 -- line# 448 : .
 -- line# 448 : src
 -- line# 448 : .
 -- line# 448 : next
 -- line# 448 : ()
 -- line# 448 : )
 -- line# 448 : ;
 -- line# 449 : // first is WhiteSpace
 -- line# 450 : while
 -- line# 450 : (
 -- line# 450 : TokenState
 -- line# 450 : .
 -- line# 450 : isWhiteSpace
 -- line# 450 : (
 -- line# 450 : context_
 -- line# 450 : )
 -- line# 450 : )
 -- line# 451 : // stop when non-WhiteSpace
 -- line# 451 : {
 -- line# 452 : tok
 -- line# 452 : .
 -- line# 452 : Append
 -- line# 452 : (
 -- line# 452 : (
 -- line# 452 : char
 -- line# 452 : )
 -- line# 452 : context_
 -- line# 452 : .
 -- line# 452 : src
 -- line# 452 : .
 -- line# 452 : next
 -- line# 452 : ()
 -- line# 452 : )
 -- line# 452 : ;
 -- line# 453 : }
 -- line# 454 : return
 -- line# 454 : tok
 -- line# 454 : ;
 -- line# 455 : }
 -- line# 456 : }
 -- line# 458 : ///////////////////////////////////////////////////////////////////
 -- line# 459 : // AlphaNumState class
 -- line# 460 : // - extracts contiguous letter and digit chars as a token
 -- line# 461 : public
 -- line# 461 : class
 -- line# 461 : AlphaNumState
 -- line# 461 : :
 -- line# 461 : TokenState
 -- line# 462 : {
 -- line# 463 : public
 -- line# 463 : AlphaNumState
 -- line# 463 : (
 -- line# 463 : TokenContext
 -- line# 463 : context
 -- line# 463 : )
 -- line# 464 : {
 -- line# 465 : context_
 -- line# 465 : =
 -- line# 465 : context
 -- line# 465 : ;
 -- line# 466 : }
 -- line# 468 : //----< keep extracting until get non-alphanum >-----------------
 -- line# 469 : override
 -- line# 469 : public
 -- line# 469 : Token
 -- line# 469 : getTok
 -- line# 469 : ()
 -- line# 470 : {
 -- line# 471 : Token
 -- line# 471 : tok
 -- line# 471 : =
 -- line# 471 : new
 -- line# 471 : Token
 -- line# 471 : ()
 -- line# 471 : ;
 -- line# 472 : tok
 -- line# 472 : .
 -- line# 472 : Append
 -- line# 472 : (
 -- line# 472 : (
 -- line# 472 : char
 -- line# 472 : )
 -- line# 472 : context_
 -- line# 472 : .
 -- line# 472 : src
 -- line# 472 : .
 -- line# 472 : next
 -- line# 472 : ()
 -- line# 472 : )
 -- line# 472 : ;
 -- line# 473 : // first is alphanum
 -- line# 474 : while
 -- line# 474 : (
 -- line# 474 : isAlphaNum
 -- line# 474 : (
 -- line# 474 : context_
 -- line# 474 : )
 -- line# 474 : )
 -- line# 475 : // stop when non-alphanum
 -- line# 475 : {
 -- line# 476 : tok
 -- line# 476 : .
 -- line# 476 : Append
 -- line# 476 : (
 -- line# 476 : (
 -- line# 476 : char
 -- line# 476 : )
 -- line# 476 : context_
 -- line# 476 : .
 -- line# 476 : src
 -- line# 476 : .
 -- line# 476 : next
 -- line# 476 : ()
 -- line# 476 : )
 -- line# 476 : ;
 -- line# 477 : }
 -- line# 478 : return
 -- line# 478 : tok
 -- line# 478 : ;
 -- line# 479 : }
 -- line# 480 : }
 -- line# 482 : ///////////////////////////////////////////////////////////////////
 -- line# 483 : // SingleLineCommentState class
 -- line# 484 : // - extracts single line comment as a token
 -- line# 485 : public
 -- line# 485 : class
 -- line# 485 : SingleLineCommentState
 -- line# 485 : :
 -- line# 485 : TokenState
 -- line# 486 : {
 -- line# 487 : public
 -- line# 487 : SingleLineCommentState
 -- line# 487 : (
 -- line# 487 : TokenContext
 -- line# 487 : context
 -- line# 487 : )
 -- line# 488 : {
 -- line# 489 : context_
 -- line# 489 : =
 -- line# 489 : context
 -- line# 489 : ;
 -- line# 490 : }
 -- line# 492 : //----< keep extracting until get newline >--------------
 -- line# 493 : override
 -- line# 493 : public
 -- line# 493 : Token
 -- line# 493 : getTok
 -- line# 493 : ()
 -- line# 494 : {
 -- line# 495 : Token
 -- line# 495 : tok
 -- line# 495 : =
 -- line# 495 : new
 -- line# 495 : Token
 -- line# 495 : ()
 -- line# 495 : ;
 -- line# 496 : tok
 -- line# 496 : .
 -- line# 496 : Append
 -- line# 496 : (
 -- line# 496 : (
 -- line# 496 : char
 -- line# 496 : )
 -- line# 496 : context_
 -- line# 496 : .
 -- line# 496 : src
 -- line# 496 : .
 -- line# 496 : next
 -- line# 496 : ()
 -- line# 496 : )
 -- line# 496 : ;
 -- line# 497 : // char is /
 -- line# 497 : tok
 -- line# 497 : .
 -- line# 497 : Append
 -- line# 497 : (
 -- line# 497 : (
 -- line# 497 : char
 -- line# 497 : )
 -- line# 497 : context_
 -- line# 497 : .
 -- line# 497 : src
 -- line# 497 : .
 -- line# 497 : next
 -- line# 497 : ()
 -- line# 497 : )
 -- line# 497 : ;
 -- line# 498 : // char is /
 -- line# 499 : char
 -- line# 499 : ch
 -- line# 499 : ;
 -- line# 500 : while
 -- line# 500 : (
 -- line# 500 : true
 -- line# 500 : )
 -- line# 501 : // stop when newline
 -- line# 501 : {
 -- line# 502 : ch
 -- line# 502 : =
 -- line# 502 : (
 -- line# 502 : char
 -- line# 502 : )
 -- line# 502 : context_
 -- line# 502 : .
 -- line# 502 : src
 -- line# 502 : .
 -- line# 502 : next
 -- line# 502 : ()
 -- line# 502 : ;
 -- line# 503 : if
 -- line# 503 : (
 -- line# 503 : ch
 -- line# 503 : ==
 -- line# 503 : '\n'
 -- line# 503 : )
 -- line# 504 : break
 -- line# 504 : ;
 -- line# 505 : tok
 -- line# 505 : .
 -- line# 505 : Append
 -- line# 505 : (
 -- line# 505 : ch
 -- line# 505 : )
 -- line# 505 : ;
 -- line# 506 : }
 -- line# 507 : return
 -- line# 507 : tok
 -- line# 507 : ;
 -- line# 508 : }
 -- line# 509 : }
 -- line# 511 : ///////////////////////////////////////////////////////////////////
 -- line# 512 : // MulitpleLineComment class
 -- line# 513 : // - extracts multiple line comment as a token
 -- line# 514 : public
 -- line# 514 : class
 -- line# 514 : MultiLineCommentState
 -- line# 514 : :
 -- line# 514 : TokenState
 -- line# 515 : {
 -- line# 516 : public
 -- line# 516 : MultiLineCommentState
 -- line# 516 : (
 -- line# 516 : TokenContext
 -- line# 516 : context
 -- line# 516 : )
 -- line# 517 : {
 -- line# 518 : context_
 -- line# 518 : =
 -- line# 518 : context
 -- line# 518 : ;
 -- line# 519 : }
 -- line# 521 : //----< keep extracting until get newline >--------------
 -- line# 522 : override
 -- line# 522 : public
 -- line# 522 : Token
 -- line# 522 : getTok
 -- line# 522 : ()
 -- line# 523 : {
 -- line# 524 : Token
 -- line# 524 : tok
 -- line# 524 : =
 -- line# 524 : new
 -- line# 524 : Token
 -- line# 524 : ()
 -- line# 524 : ;
 -- line# 525 : tok
 -- line# 525 : .
 -- line# 525 : Append
 -- line# 525 : (
 -- line# 525 : (
 -- line# 525 : char
 -- line# 525 : )
 -- line# 525 : context_
 -- line# 525 : .
 -- line# 525 : src
 -- line# 525 : .
 -- line# 525 : next
 -- line# 525 : ()
 -- line# 525 : )
 -- line# 525 : ;
 -- line# 526 : // char is /
 -- line# 526 : tok
 -- line# 526 : .
 -- line# 526 : Append
 -- line# 526 : (
 -- line# 526 : (
 -- line# 526 : char
 -- line# 526 : )
 -- line# 526 : context_
 -- line# 526 : .
 -- line# 526 : src
 -- line# 526 : .
 -- line# 526 : next
 -- line# 526 : ()
 -- line# 526 : )
 -- line# 526 : ;
 -- line# 527 : // char is *
 -- line# 528 : char
 -- line# 528 : ch
 -- line# 528 : =
 -- line# 528 : ' '
 -- line# 528 : ,
 -- line# 528 : prevCh
 -- line# 528 : =
 -- line# 528 : ' '
 -- line# 528 : ;
 -- line# 529 : while
 -- line# 529 : (
 -- line# 529 : true
 -- line# 529 : )
 -- line# 530 : // stop when newline
 -- line# 530 : {
 -- line# 531 : prevCh
 -- line# 531 : =
 -- line# 531 : ch
 -- line# 531 : ;
 -- line# 532 : ch
 -- line# 532 : =
 -- line# 532 : (
 -- line# 532 : char
 -- line# 532 : )
 -- line# 532 : context_
 -- line# 532 : .
 -- line# 532 : src
 -- line# 532 : .
 -- line# 532 : next
 -- line# 532 : ()
 -- line# 532 : ;
 -- line# 533 : tok
 -- line# 533 : .
 -- line# 533 : Append
 -- line# 533 : (
 -- line# 533 : ch
 -- line# 533 : )
 -- line# 533 : ;
 -- line# 534 : if
 -- line# 534 : (
 -- line# 534 : prevCh
 -- line# 534 : ==
 -- line# 534 : '*'
 -- line# 534 : &&
 -- line# 534 : ch
 -- line# 534 : ==
 -- line# 534 : '/'
 -- line# 534 : )
 -- line# 535 : break
 -- line# 535 : ;
 -- line# 536 : }
 -- line# 537 : return
 -- line# 537 : tok
 -- line# 537 : ;
 -- line# 538 : }
 -- line# 539 : }
 -- line# 541 : ///////////////////////////////////////////////////////////////////
 -- line# 542 : // SingleQuoteState class
 -- line# 543 : // - extracts single quoted char as a token with quotes
 -- line# 544 : public
 -- line# 544 : class
 -- line# 544 : SingleQuoteState
 -- line# 544 : :
 -- line# 544 : TokenState
 -- line# 545 : {
 -- line# 546 : public
 -- line# 546 : SingleQuoteState
 -- line# 546 : (
 -- line# 546 : TokenContext
 -- line# 546 : context
 -- line# 546 : )
 -- line# 547 : {
 -- line# 548 : context_
 -- line# 548 : =
 -- line# 548 : context
 -- line# 548 : ;
 -- line# 549 : }
 -- line# 552 : //----< keep extracting until get end quote >--------------------
 -- line# 553 : override
 -- line# 553 : public
 -- line# 553 : Token
 -- line# 553 : getTok
 -- line# 553 : ()
 -- line# 554 : {
 -- line# 555 : Token
 -- line# 555 : tok
 -- line# 555 : =
 -- line# 555 : new
 -- line# 555 : Token
 -- line# 555 : ()
 -- line# 555 : ;
 -- line# 556 : tok
 -- line# 556 : .
 -- line# 556 : Append
 -- line# 556 : (
 -- line# 556 : (
 -- line# 556 : char
 -- line# 556 : )
 -- line# 556 : context_
 -- line# 556 : .
 -- line# 556 : src
 -- line# 556 : .
 -- line# 556 : next
 -- line# 556 : ()
 -- line# 556 : )
 -- line# 556 : ;
 -- line# 557 : // char is '\''
 -- line# 558 : while
 -- line# 558 : (
 -- line# 558 : true
 -- line# 558 : )
 -- line# 559 : {
 -- line# 560 : char
 -- line# 560 : ch
 -- line# 560 : =
 -- line# 560 : (
 -- line# 560 : char
 -- line# 560 : )
 -- line# 560 : context_
 -- line# 560 : .
 -- line# 560 : src
 -- line# 560 : .
 -- line# 560 : next
 -- line# 560 : ()
 -- line# 560 : ;
 -- line# 561 : tok
 -- line# 561 : .
 -- line# 561 : Append
 -- line# 561 : (
 -- line# 561 : ch
 -- line# 561 : )
 -- line# 561 : ;
 -- line# 562 : if
 -- line# 562 : (
 -- line# 562 : ch
 -- line# 562 : ==
 -- line# 562 : '\''
 -- line# 562 : &&
 -- line# 562 : !
 -- line# 562 : isEscaped
 -- line# 562 : (
 -- line# 562 : tok
 -- line# 562 : )
 -- line# 562 : )
 -- line# 563 : break
 -- line# 563 : ;
 -- line# 564 : }
 -- line# 565 : return
 -- line# 565 : tok
 -- line# 565 : ;
 -- line# 566 : }
 -- line# 567 : }
 -- line# 569 : ///////////////////////////////////////////////////////////////////
 -- line# 570 : // DoubleQuoteState class
 -- line# 571 : // - extracts text in quotes as a token
 -- line# 572 : public
 -- line# 572 : class
 -- line# 572 : DoubleQuoteState
 -- line# 572 : :
 -- line# 572 : TokenState
 -- line# 573 : {
 -- line# 574 : public
 -- line# 574 : DoubleQuoteState
 -- line# 574 : (
 -- line# 574 : TokenContext
 -- line# 574 : context
 -- line# 574 : )
 -- line# 575 : {
 -- line# 576 : context_
 -- line# 576 : =
 -- line# 576 : context
 -- line# 576 : ;
 -- line# 577 : }
 -- line# 579 : //----< keep extracting until get end quote >--------------------
 -- line# 580 : override
 -- line# 580 : public
 -- line# 580 : Token
 -- line# 580 : getTok
 -- line# 580 : ()
 -- line# 581 : {
 -- line# 582 : Token
 -- line# 582 : tok
 -- line# 582 : =
 -- line# 582 : new
 -- line# 582 : Token
 -- line# 582 : ()
 -- line# 582 : ;
 -- line# 583 : tok
 -- line# 583 : .
 -- line# 583 : Append
 -- line# 583 : (
 -- line# 583 : (
 -- line# 583 : char
 -- line# 583 : )
 -- line# 583 : context_
 -- line# 583 : .
 -- line# 583 : src
 -- line# 583 : .
 -- line# 583 : next
 -- line# 583 : ()
 -- line# 583 : )
 -- line# 583 : ;
 -- line# 584 : // char is "\""
 -- line# 585 : while
 -- line# 585 : (
 -- line# 585 : true
 -- line# 585 : )
 -- line# 586 : {
 -- line# 587 : char
 -- line# 587 : ch
 -- line# 587 : =
 -- line# 587 : (
 -- line# 587 : char
 -- line# 587 : )
 -- line# 587 : context_
 -- line# 587 : .
 -- line# 587 : src
 -- line# 587 : .
 -- line# 587 : next
 -- line# 587 : ()
 -- line# 587 : ;
 -- line# 588 : tok
 -- line# 588 : .
 -- line# 588 : Append
 -- line# 588 : (
 -- line# 588 : ch
 -- line# 588 : )
 -- line# 588 : ;
 -- line# 589 : if
 -- line# 589 : (
 -- line# 589 : ch
 -- line# 589 : ==
 -- line# 589 : '\"'
 -- line# 589 : &&
 -- line# 589 : !
 -- line# 589 : isEscaped
 -- line# 589 : (
 -- line# 589 : tok
 -- line# 589 : )
 -- line# 589 : )
 -- line# 590 : break
 -- line# 590 : ;
 -- line# 591 : }
 -- line# 592 : return
 -- line# 592 : tok
 -- line# 592 : ;
 -- line# 593 : }
 -- line# 594 : }
 -- line# 596 : ///////////////////////////////////////////////////////////////////
 -- line# 597 : // PunctuationState class
 -- line# 598 : // - extracts contiguous punctuation chars as a token
 -- line# 599 : public
 -- line# 599 : class
 -- line# 599 : PunctuationState
 -- line# 599 : :
 -- line# 599 : TokenState
 -- line# 600 : {
 -- line# 601 : public
 -- line# 601 : PunctuationState
 -- line# 601 : (
 -- line# 601 : TokenContext
 -- line# 601 : context
 -- line# 601 : )
 -- line# 602 : {
 -- line# 603 : context_
 -- line# 603 : =
 -- line# 603 : context
 -- line# 603 : ;
 -- line# 604 : }
 -- line# 606 : //----< keep extracting until get non-punctuator >---------------
 -- line# 609 : 
/*
     * Here is where we handle single char and two char special tokens
     * as well as other punctuators.
     */
 -- line# 610 : override
 -- line# 610 : public
 -- line# 610 : Token
 -- line# 610 : getTok
 -- line# 610 : ()
 -- line# 611 : {
 -- line# 613 : // is this a two char special token?
 -- line# 613 : Token
 -- line# 613 : test
 -- line# 613 : =
 -- line# 613 : new
 -- line# 613 : Token
 -- line# 613 : ()
 -- line# 613 : ;
 -- line# 614 : test
 -- line# 614 : .
 -- line# 614 : Append
 -- line# 614 : (
 -- line# 614 : (
 -- line# 614 : char
 -- line# 614 : )
 -- line# 614 : context_
 -- line# 614 : .
 -- line# 614 : src
 -- line# 614 : .
 -- line# 614 : peek
 -- line# 614 : ()
 -- line# 614 : )
 -- line# 614 : ;
 -- line# 615 : test
 -- line# 615 : .
 -- line# 615 : Append
 -- line# 615 : (
 -- line# 615 : (
 -- line# 615 : char
 -- line# 615 : )
 -- line# 615 : context_
 -- line# 615 : .
 -- line# 615 : src
 -- line# 615 : .
 -- line# 615 : peek
 -- line# 615 : (
 -- line# 615 : 1
 -- line# 615 : )
 -- line# 615 : )
 -- line# 615 : ;
 -- line# 616 : if
 -- line# 616 : (
 -- line# 616 : twoCharTokens_
 -- line# 616 : .
 -- line# 616 : Contains
 -- line# 616 : (
 -- line# 616 : test
 -- line# 616 : .
 -- line# 616 : ToString
 -- line# 616 : ()
 -- line# 616 : )
 -- line# 616 : )
 -- line# 617 : {
 -- line# 618 : context_
 -- line# 618 : .
 -- line# 618 : src
 -- line# 618 : .
 -- line# 618 : next
 -- line# 618 : ()
 -- line# 618 : ;
 -- line# 619 : // pop peeked char
 -- line# 619 : context_
 -- line# 619 : .
 -- line# 619 : src
 -- line# 619 : .
 -- line# 619 : next
 -- line# 619 : ()
 -- line# 619 : ;
 -- line# 620 : // pop peeked char
 -- line# 620 : return
 -- line# 620 : test
 -- line# 620 : ;
 -- line# 621 : }
 -- line# 623 : // is this a single char special token?
 -- line# 623 : Token
 -- line# 623 : tok
 -- line# 623 : =
 -- line# 623 : new
 -- line# 623 : Token
 -- line# 623 : ()
 -- line# 623 : ;
 -- line# 624 : tok
 -- line# 624 : .
 -- line# 624 : Append
 -- line# 624 : (
 -- line# 624 : (
 -- line# 624 : char
 -- line# 624 : )
 -- line# 624 : context_
 -- line# 624 : .
 -- line# 624 : src
 -- line# 624 : .
 -- line# 624 : next
 -- line# 624 : ()
 -- line# 624 : )
 -- line# 624 : ;
 -- line# 625 : // pop first punctuator
 -- line# 625 : if
 -- line# 625 : (
 -- line# 625 : oneCharTokens_
 -- line# 625 : .
 -- line# 625 : Contains
 -- line# 625 : (
 -- line# 625 : tok
 -- line# 625 : .
 -- line# 625 : ToString
 -- line# 625 : ()
 -- line# 625 : )
 -- line# 625 : )
 -- line# 626 : return
 -- line# 626 : tok
 -- line# 626 : ;
 -- line# 629 : // not special token, so continue collecting punctuation chars
 -- line# 629 : while
 -- line# 629 : (
 -- line# 629 : TokenState
 -- line# 629 : .
 -- line# 629 : isPunctuation
 -- line# 629 : (
 -- line# 629 : context_
 -- line# 629 : )
 -- line# 629 : )
 -- line# 630 : {
 -- line# 632 : // check for other special cases starting in middle of punctuator
 -- line# 632 : if
 -- line# 632 : (
 -- line# 633 : isMultiLineComment
 -- line# 633 : (
 -- line# 633 : context_
 -- line# 633 : )
 -- line# 633 : ||
 -- line# 633 : isSingleLineComment
 -- line# 633 : (
 -- line# 633 : context_
 -- line# 633 : )
 -- line# 633 : ||
 -- line# 634 : isDoubleQuote
 -- line# 634 : (
 -- line# 634 : context_
 -- line# 634 : )
 -- line# 634 : ||
 -- line# 634 : isSingleQuote
 -- line# 634 : (
 -- line# 634 : context_
 -- line# 634 : )
 -- line# 635 : )
 -- line# 636 : break
 -- line# 636 : ;
 -- line# 637 : tok
 -- line# 637 : .
 -- line# 637 : Append
 -- line# 637 : (
 -- line# 637 : (
 -- line# 637 : char
 -- line# 637 : )
 -- line# 637 : context_
 -- line# 637 : .
 -- line# 637 : src
 -- line# 637 : .
 -- line# 637 : next
 -- line# 637 : ()
 -- line# 637 : )
 -- line# 637 : ;
 -- line# 638 : }
 -- line# 639 : return
 -- line# 639 : tok
 -- line# 639 : ;
 -- line# 640 : }
 -- line# 641 : }
 -- line# 643 : ///////////////////////////////////////////////////////////////////
 -- line# 644 : // TokenSourceFile class
 -- line# 645 : // - extracts integers from token source
 -- line# 646 : // - Streams often use terminators that can't be represented by
 -- line# 647 : //   a character, so we collect all elements as ints
 -- line# 648 : // - keeps track of the line number where a token is found
 -- line# 649 : // - uses StreamReader which correctly handles byte order mark
 -- line# 650 : //   characters and alternate text encodings.
 -- line# 651 : public
 -- line# 651 : class
 -- line# 651 : TokenSourceFile
 -- line# 651 : :
 -- line# 651 : ITokenSource
 -- line# 652 : {
 -- line# 653 : public
 -- line# 653 : int
 -- line# 653 : lineCount
 -- line# 653 : {
 -- line# 653 : get
 -- line# 653 : ;
 -- line# 653 : set
 -- line# 653 : ;
 -- line# 653 : }
 -- line# 653 : =
 -- line# 653 : 1
 -- line# 653 : ;
 -- line# 654 : private
 -- line# 654 : System
 -- line# 654 : .
 -- line# 654 : IO
 -- line# 654 : .
 -- line# 654 : StreamReader
 -- line# 654 : fs_
 -- line# 654 : ;
 -- line# 655 : // physical source of text
 -- line# 655 : private
 -- line# 655 : List
 -- line# 655 : <
 -- line# 655 : int
 -- line# 655 : >
 -- line# 655 : charQ_
 -- line# 655 : =
 -- line# 655 : new
 -- line# 655 : List
 -- line# 655 : <
 -- line# 655 : int
 -- line# 655 : >
 -- line# 655 : ()
 -- line# 655 : ;
 -- line# 656 : // enqueing ints but using as chars
 -- line# 656 : private
 -- line# 656 : TokenContext
 -- line# 656 : context_
 -- line# 656 : ;
 -- line# 658 : public
 -- line# 658 : TokenSourceFile
 -- line# 658 : (
 -- line# 658 : TokenContext
 -- line# 658 : context
 -- line# 658 : )
 -- line# 659 : {
 -- line# 660 : context_
 -- line# 660 : =
 -- line# 660 : context
 -- line# 660 : ;
 -- line# 661 : }
 -- line# 663 : //----< attempt to open file with a System.IO.StreamReader >-----
 -- line# 664 : public
 -- line# 664 : bool
 -- line# 664 : open
 -- line# 664 : (
 -- line# 664 : string
 -- line# 664 : path
 -- line# 664 : )
 -- line# 665 : {
 -- line# 666 : try
 -- line# 667 : {
 -- line# 668 : fs_
 -- line# 668 : =
 -- line# 668 : new
 -- line# 668 : System
 -- line# 668 : .
 -- line# 668 : IO
 -- line# 668 : .
 -- line# 668 : StreamReader
 -- line# 668 : (
 -- line# 668 : path
 -- line# 668 : ,
 -- line# 668 : true
 -- line# 668 : )
 -- line# 668 : ;
 -- line# 669 : context_
 -- line# 669 : .
 -- line# 669 : currentState_
 -- line# 669 : =
 -- line# 669 : TokenState
 -- line# 669 : .
 -- line# 669 : nextState
 -- line# 669 : (
 -- line# 669 : context_
 -- line# 669 : )
 -- line# 669 : ;
 -- line# 670 : }
 -- line# 671 : catch
 -- line# 671 : (
 -- line# 671 : Exception
 -- line# 671 : ex
 -- line# 671 : )
 -- line# 672 : {
 -- line# 673 : Console
 -- line# 673 : .
 -- line# 673 : Write
 -- line# 673 : (
 -- line# 673 : "\n  {0}\n"
 -- line# 673 : ,
 -- line# 673 : ex
 -- line# 673 : .
 -- line# 673 : Message
 -- line# 673 : )
 -- line# 673 : ;
 -- line# 674 : return
 -- line# 674 : false
 -- line# 674 : ;
 -- line# 675 : }
 -- line# 676 : return
 -- line# 676 : true
 -- line# 676 : ;
 -- line# 677 : }
 -- line# 679 : //----< close file >---------------------------------------------
 -- line# 680 : public
 -- line# 680 : void
 -- line# 680 : close
 -- line# 680 : ()
 -- line# 681 : {
 -- line# 682 : fs_
 -- line# 682 : .
 -- line# 682 : Close
 -- line# 682 : ()
 -- line# 682 : ;
 -- line# 683 : }
 -- line# 685 : //----< extract the next available integer >---------------------
 -- line# 688 : 
/*
     *  - checks to see if previously enqueued peeked ints are available
     *  - if not, reads from stream
     */
 -- line# 689 : public
 -- line# 689 : int
 -- line# 689 : next
 -- line# 689 : ()
 -- line# 690 : {
 -- line# 691 : int
 -- line# 691 : ch
 -- line# 691 : ;
 -- line# 692 : if
 -- line# 692 : (
 -- line# 692 : charQ_
 -- line# 692 : .
 -- line# 692 : Count
 -- line# 692 : ==
 -- line# 692 : 0
 -- line# 692 : )
 -- line# 693 : // no saved peeked ints
 -- line# 693 : {
 -- line# 694 : if
 -- line# 694 : (
 -- line# 694 : end
 -- line# 694 : ()
 -- line# 694 : )
 -- line# 695 : return
 -- line# 695 : -
 -- line# 695 : 1
 -- line# 695 : ;
 -- line# 696 : ch
 -- line# 696 : =
 -- line# 696 : fs_
 -- line# 696 : .
 -- line# 696 : Read
 -- line# 696 : ()
 -- line# 696 : ;
 -- line# 697 : }
 -- line# 698 : else
 -- line# 699 : // has saved peeked ints, so use the first
 -- line# 699 : {
 -- line# 700 : ch
 -- line# 700 : =
 -- line# 700 : charQ_
 -- line# 700 : [
 -- line# 700 : 0
 -- line# 700 : ]
 -- line# 700 : ;
 -- line# 701 : charQ_
 -- line# 701 : .
 -- line# 701 : RemoveAt
 -- line# 701 : (
 -- line# 701 : 0
 -- line# 701 : )
 -- line# 701 : ;
 -- line# 702 : // pop from queue
 -- line# 702 : }
 -- line# 703 : if
 -- line# 703 : (
 -- line# 703 : (
 -- line# 703 : char
 -- line# 703 : )
 -- line# 703 : ch
 -- line# 703 : ==
 -- line# 703 : '\n'
 -- line# 703 : )
 -- line# 704 : // track the number of newlines seen so far
 -- line# 704 : ++
 -- line# 704 : lineCount
 -- line# 704 : ;
 -- line# 705 : return
 -- line# 705 : ch
 -- line# 705 : ;
 -- line# 706 : }
 -- line# 708 : //----< peek n ints into source without extracting them >--------
 -- line# 714 : 
/*
     *  - This is an organizing prinicple that makes tokenizing easier
     *  - We enqueue because file streams only allow peeking at the first int
     *    and even that isn't always reliable if an error occurred.
     *  - When we look for two punctuator tokens, like ==, !=, etc. we want
     *    to detect their presence without removing them from the stream.
     */
 -- line# 715 : public
 -- line# 715 : int
 -- line# 715 : peek
 -- line# 715 : (
 -- line# 715 : int
 -- line# 715 : n
 -- line# 715 : =
 -- line# 715 : 0
 -- line# 715 : )
 -- line# 716 : {
 -- line# 717 : if
 -- line# 717 : (
 -- line# 717 : n
 -- line# 717 : <
 -- line# 717 : charQ_
 -- line# 717 : .
 -- line# 717 : Count
 -- line# 717 : )
 -- line# 718 : // nth already peeked, so return it
 -- line# 718 : {
 -- line# 719 : return
 -- line# 719 : charQ_
 -- line# 719 : [
 -- line# 719 : n
 -- line# 719 : ]
 -- line# 719 : ;
 -- line# 720 : }
 -- line# 721 : else
 -- line# 722 : // nth int not yet peeked
 -- line# 722 : {
 -- line# 723 : for
 -- line# 723 : (
 -- line# 723 : int
 -- line# 723 : i
 -- line# 723 : =
 -- line# 723 : charQ_
 -- line# 723 : .
 -- line# 723 : Count
 -- line# 723 : ;
 -- line# 723 : i
 -- line# 723 : <
 -- line# 723 : =
 -- line# 723 : n
 -- line# 723 : ;
 -- line# 723 : ++
 -- line# 723 : i
 -- line# 723 : )
 -- line# 724 : {
 -- line# 725 : if
 -- line# 725 : (
 -- line# 725 : end
 -- line# 725 : ()
 -- line# 725 : )
 -- line# 726 : return
 -- line# 726 : -
 -- line# 726 : 1
 -- line# 726 : ;
 -- line# 727 : charQ_
 -- line# 727 : .
 -- line# 727 : Add
 -- line# 727 : (
 -- line# 727 : fs_
 -- line# 727 : .
 -- line# 727 : Read
 -- line# 727 : ()
 -- line# 727 : )
 -- line# 727 : ;
 -- line# 728 : // read and enqueue
 -- line# 728 : }
 -- line# 729 : return
 -- line# 729 : charQ_
 -- line# 729 : [
 -- line# 729 : n
 -- line# 729 : ]
 -- line# 729 : ;
 -- line# 730 : // now return the last peeked
 -- line# 730 : }
 -- line# 731 : }
 -- line# 733 : //----< reached the end of the file stream? >--------------------
 -- line# 734 : public
 -- line# 734 : bool
 -- line# 734 : end
 -- line# 734 : ()
 -- line# 735 : {
 -- line# 736 : return
 -- line# 736 : fs_
 -- line# 736 : .
 -- line# 736 : EndOfStream
 -- line# 736 : ;
 -- line# 737 : }
 -- line# 738 : }
 -- line# 740 : #
 -- line# 740 : if
 -- line# 740 : (
 -- line# 740 : TEST_TOKER
 -- line# 740 : )
 -- line# 742 : class
 -- line# 742 : DemoToker
 -- line# 743 : {
 -- line# 745 : //----< tokenize a test file >-----------------------------------
 -- line# 748 : 
/*
     * This method allows us to easily test against several different
     * files with special cases that have to be handled correctly.
     */
 -- line# 749 : static
 -- line# 749 : bool
 -- line# 749 : testToker
 -- line# 749 : (
 -- line# 749 : string
 -- line# 749 : path
 -- line# 749 : )
 -- line# 750 : {
 -- line# 751 : Toker
 -- line# 751 : toker
 -- line# 751 : =
 -- line# 751 : new
 -- line# 751 : Toker
 -- line# 751 : ()
 -- line# 751 : ;
 -- line# 753 : string
 -- line# 753 : fqf
 -- line# 753 : =
 -- line# 753 : System
 -- line# 753 : .
 -- line# 753 : IO
 -- line# 753 : .
 -- line# 753 : Path
 -- line# 753 : .
 -- line# 753 : GetFullPath
 -- line# 753 : (
 -- line# 753 : path
 -- line# 753 : )
 -- line# 753 : ;
 -- line# 754 : if
 -- line# 754 : (
 -- line# 754 : !
 -- line# 754 : toker
 -- line# 754 : .
 -- line# 754 : open
 -- line# 754 : (
 -- line# 754 : fqf
 -- line# 754 : )
 -- line# 754 : )
 -- line# 755 : {
 -- line# 756 : Console
 -- line# 756 : .
 -- line# 756 : Write
 -- line# 756 : (
 -- line# 756 : "\n can't open {0}\n"
 -- line# 756 : ,
 -- line# 756 : fqf
 -- line# 756 : )
 -- line# 756 : ;
 -- line# 757 : return
 -- line# 757 : false
 -- line# 757 : ;
 -- line# 758 : }
 -- line# 759 : else
 -- line# 760 : {
 -- line# 761 : Console
 -- line# 761 : .
 -- line# 761 : Write
 -- line# 761 : (
 -- line# 761 : "\n  processing file: {0}"
 -- line# 761 : ,
 -- line# 761 : fqf
 -- line# 761 : )
 -- line# 761 : ;
 -- line# 762 : }
 -- line# 763 : while
 -- line# 763 : (
 -- line# 763 : !
 -- line# 763 : toker
 -- line# 763 : .
 -- line# 763 : isDone
 -- line# 763 : ()
 -- line# 763 : )
 -- line# 764 : {
 -- line# 765 : Token
 -- line# 765 : tok
 -- line# 765 : =
 -- line# 765 : toker
 -- line# 765 : .
 -- line# 765 : getTok
 -- line# 765 : ()
 -- line# 765 : ;
 -- line# 766 : if
 -- line# 766 : (
 -- line# 766 : Toker
 -- line# 766 : .
 -- line# 766 : isMultipleLineComment
 -- line# 766 : (
 -- line# 766 : tok
 -- line# 766 : )
 -- line# 766 : )
 -- line# 767 : // this is a cosmetic
 -- line# 767 : tok
 -- line# 767 : .
 -- line# 767 : Insert
 -- line# 767 : (
 -- line# 767 : 0
 -- line# 767 : ,
 -- line# 767 : '\n'
 -- line# 767 : )
 -- line# 767 : ;
 -- line# 768 : Console
 -- line# 768 : .
 -- line# 768 : Write
 -- line# 768 : (
 -- line# 768 : "\n -- line#{0, 4} : {1}"
 -- line# 768 : ,
 -- line# 768 : toker
 -- line# 768 : .
 -- line# 768 : lineCount
 -- line# 768 : ()
 -- line# 768 : ,
 -- line# 768 : tok
 -- line# 768 : )
 -- line# 768 : ;
 -- line# 769 : }
 -- line# 770 : toker
 -- line# 770 : .
 -- line# 770 : close
 -- line# 770 : ()
 -- line# 770 : ;
 -- line# 771 : return
 -- line# 771 : true
 -- line# 771 : ;
 -- line# 772 : }
 -- line# 773 : static
 -- line# 773 : void
 -- line# 773 : Main
 -- line# 773 : (
 -- line# 773 : string
 -- line# 773 : []
 -- line# 773 : args
 -- line# 773 : )
 -- line# 774 : {
 -- line# 775 : Console
 -- line# 775 : .
 -- line# 775 : Write
 -- line# 775 : (
 -- line# 775 : "\n  Demonstrate Toker class"
 -- line# 775 : )
 -- line# 775 : ;
 -- line# 776 : Console
 -- line# 776 : .
 -- line# 776 : Write
 -- line# 776 : (
 -- line# 776 : "\n ========================="
 -- line# 776 : )
 -- line# 776 : ;
 -- line# 778 : StringBuilder
 -- line# 778 : msg
 -- line# 778 : =
 -- line# 778 : new
 -- line# 778 : StringBuilder
 -- line# 778 : ()
 -- line# 778 : ;
 -- line# 779 : msg
 -- line# 779 : .
 -- line# 779 : Append
 -- line# 779 : (
 -- line# 779 : "\n  Some things this Instructor's Solution does for CSE681 Project #2:"
 -- line# 779 : )
 -- line# 779 : ;
 -- line# 780 : msg
 -- line# 780 : .
 -- line# 780 : Append
 -- line# 780 : (
 -- line# 780 : "\n  - collect comments as tokens"
 -- line# 780 : )
 -- line# 780 : ;
 -- line# 781 : msg
 -- line# 781 : .
 -- line# 781 : Append
 -- line# 781 : (
 -- line# 781 : "\n  - collect double quoted strings as tokens"
 -- line# 781 : )
 -- line# 781 : ;
 -- line# 782 : msg
 -- line# 782 : .
 -- line# 782 : Append
 -- line# 782 : (
 -- line# 782 : "\n  - collect single quoted strings as tokens"
 -- line# 782 : )
 -- line# 782 : ;
 -- line# 783 : msg
 -- line# 783 : .
 -- line# 783 : Append
 -- line# 783 : (
 -- line# 783 : "\n  - collect specified single characters as tokens"
 -- line# 783 : )
 -- line# 783 : ;
 -- line# 784 : msg
 -- line# 784 : .
 -- line# 784 : Append
 -- line# 784 : (
 -- line# 784 : "\n  - collect specified character pairs as tokens"
 -- line# 784 : )
 -- line# 784 : ;
 -- line# 785 : msg
 -- line# 785 : .
 -- line# 785 : Append
 -- line# 785 : (
 -- line# 785 : "\n  - integrate with a SemiExpression collector"
 -- line# 785 : )
 -- line# 785 : ;
 -- line# 786 : msg
 -- line# 786 : .
 -- line# 786 : Append
 -- line# 786 : (
 -- line# 786 : "\n  - provide the required package structure"
 -- line# 786 : )
 -- line# 786 : ;
 -- line# 787 : msg
 -- line# 787 : .
 -- line# 787 : Append
 -- line# 787 : (
 -- line# 787 : "\n"
 -- line# 787 : )
 -- line# 787 : ;
 -- line# 789 : Console
 -- line# 789 : .
 -- line# 789 : Write
 -- line# 789 : (
 -- line# 789 : msg
 -- line# 789 : )
 -- line# 789 : ;
 -- line# 791 : testToker
 -- line# 791 : (
 -- line# 791 : "../../Test.txt"
 -- line# 791 : )
 -- line# 791 : ;
 -- line# 792 : testToker
 -- line# 792 : (
 -- line# 792 : "../../Toker.cs"
 -- line# 792 : )
 -- line# 792 : ;
 -- line# 794 : Console
 -- line# 794 : .
 -- line# 794 : Write
 -- line# 794 : (
 -- line# 794 : "\n\n"
 -- line# 794 : )
 -- line# 794 : ;
 -- line# 795 : }
 -- line# 796 : }
 -- line# 797 : }
 -- line# 799 : #
 -- line# 799 : endif
 -- line# 800 : 


